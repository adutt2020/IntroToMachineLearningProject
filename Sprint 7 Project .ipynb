{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 7: Intro to Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. \n",
    "\n",
    "I have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, I will need to develop a model that will pick the right plan. \n",
    "\n",
    "I will develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing \n",
    "\n",
    "Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Review and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data looks clean! However, I will be converting the 'calls' and 'messages' to integer data type to help with run speed when figuring out which model will be ideal for use in this case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int64  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int64  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df['calls'] = df['calls'].astype('int64')\n",
    "df['messages'] = df['messages'].astype('int64')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into a training set, validation set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train, validate, test = \\\n",
    "              np.split(df.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "train_features = train.drop(['is_ultra'], axis=1)\n",
    "train_target = train['is_ultra']\n",
    "\n",
    "validate_features = validate.drop(['is_ultra'], axis=1)\n",
    "validate_target = validate['is_ultra']\n",
    "\n",
    "test_features = test.drop(['is_ultra'], axis=1)\n",
    "test_target = test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into 60% training, 20% data, and 20%  as it's a 3:1:1 ratio, which made the most sense. Then I designated 20% of the data to create the validation set, then from the remaining 80%, I took 25% to make the testing set. This follows the ratio of 3:1:1 or 60%, 20%, and 20% since after the first split, 80% of the initial data remained, and 0.8 * 0.25 = 0.2, representing a second 20% share of the full data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables for features and targets\n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score using train data is: 100.0\n",
      "Model accuracy score using validation data is: 72.93934681181959\n"
     ]
    }
   ],
   "source": [
    "# No hyperparameter tuning\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(train_features, train_target)\n",
    "\n",
    "dt_predict_train = dt_model.predict(train_features)\n",
    "dt_predict_valid = dt_model.predict(validate_features)\n",
    "\n",
    "print(\"Model accuracy score using train data is:\", accuracy_score(train_target, dt_predict_train) * 100)\n",
    "print(\"Model accuracy score using validation data is:\", accuracy_score(validate_target, dt_predict_valid) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : Train data accuracy is 75.4149377593361 and validation data accuracy is 72.31726283048211\n",
      "max_depth = 2 : Train data accuracy is 78.7344398340249 and validation data accuracy is 76.98289269051321\n",
      "max_depth = 3 : Train data accuracy is 79.92738589211619 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 4 : Train data accuracy is 79.9792531120332 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 5 : Train data accuracy is 81.58713692946058 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 6 : Train data accuracy is 82.88381742738589 and validation data accuracy is 78.69362363919129\n",
      "max_depth = 7 : Train data accuracy is 83.97302904564316 and validation data accuracy is 78.0715396578538\n",
      "max_depth = 8 : Train data accuracy is 85.47717842323651 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 9 : Train data accuracy is 86.35892116182573 and validation data accuracy is 79.00466562986003\n",
      "max_depth = 10 : Train data accuracy is 87.65560165975104 and validation data accuracy is 79.16018662519441\n"
     ]
    }
   ],
   "source": [
    "# With hyperparameter tunning\n",
    "for depth in range(1, 11):\n",
    "    dtree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    dtree_model.fit(train_features, train_target)\n",
    "    \n",
    "    predict_train = dtree_model.predict(train_features) \n",
    "    predict_valid = dtree_model.predict(validate_features) \n",
    "    \n",
    "    acc_train = accuracy_score(train_target, predict_train) * 100\n",
    "    acc_valid = accuracy_score(validate_target, predict_valid) * 100\n",
    "        \n",
    "    print('max_depth =', depth, ': ', end='')\n",
    "    print(f'Train data accuracy is {acc_train} and validation data accuracy is {acc_valid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores between the two models are significantly different, suggesting the presence of overfitting. Which is why performing the hyperparameter tuning to optimize the model's performance had to be done. \n",
    "\n",
    "The highest accuracy score of 87.65% is for the training data and 79.16% for the validation data when using a max_depth of 10 in the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score using train data is: 100.0\n",
      "Model accuracy score using validation data is: 80.40435458786936\n"
     ]
    }
   ],
   "source": [
    "# No hyperparameter tuning\n",
    "rforest = RandomForestClassifier() \n",
    "rforest.fit(train_features, train_target) \n",
    "\n",
    "rf_predict_train = rforest.predict(train_features)\n",
    "rf_predict_valid = rforest.predict(validate_features)\n",
    "\n",
    "print(\"Model accuracy score using train data is:\", accuracy_score(train_target, rf_predict_train) * 100)\n",
    "print(\"Model accuracy score using validation data is:\", accuracy_score(validate_target, rf_predict_valid) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 : Train data accuracy is 88.95 and validation data accuracy is 80.25\n",
      "n_estimators = 20 : Train data accuracy is 88.95 and validation data accuracy is 80.56\n",
      "n_estimators = 30 : Train data accuracy is 89.16 and validation data accuracy is 80.72\n",
      "n_estimators = 40 : Train data accuracy is 89.26 and validation data accuracy is 80.09\n",
      "n_estimators = 50 : Train data accuracy is 89.21 and validation data accuracy is 79.78\n",
      "n_estimators = 60 : Train data accuracy is 89.47 and validation data accuracy is 80.09\n",
      "n_estimators = 70 : Train data accuracy is 89.26 and validation data accuracy is 80.25\n",
      "n_estimators = 80 : Train data accuracy is 89.26 and validation data accuracy is 80.56\n",
      "n_estimators = 90 : Train data accuracy is 89.21 and validation data accuracy is 80.25\n",
      "n_estimators = 100 : Train data accuracy is 89.16 and validation data accuracy is 80.25\n"
     ]
    }
   ],
   "source": [
    "# With hyperparameter tunning\n",
    "\n",
    "for est in range(10, 101, 10):\n",
    "    rf_model = RandomForestClassifier(random_state=54321, max_depth=10, n_estimators=est)\n",
    "    rf_model.fit(train_features, train_target) \n",
    "\n",
    "    rf_predict_train_tunning = rf_model.predict(train_features) \n",
    "    rf_predict_valid_tunning = rf_model.predict(validate_features) \n",
    "\n",
    "    acc_train = accuracy_score(train_target, rf_predict_train_tunning) * 100\n",
    "    acc_valid = accuracy_score(validate_target, rf_predict_valid_tunning) * 100\n",
    "\n",
    "    print('n_estimators =', est, ': ', end='')\n",
    "    print(f'Train data accuracy is {acc_train.round(2)} and validation data accuracy is {acc_valid.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observed a significant accuracy gap in the random forest model, indicating overfitting. To address this issue, I applied hyperparameter tuning. Based on previous models, I found that setting max_depth to 10 yielded the best accuracy. Therefore, in this model, I focused on tuning the n_estimators parameter to find the optimal number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model based on training set: 0.7012448132780082\n",
      "Accuracy of logistic regression model based on validation set: 0.7045101088646968\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "lr_model = LogisticRegression(random_state=54321, solver='liblinear') \n",
    "lr_model.fit(train_features, train_target) \n",
    "score_train = lr_model.score(train_features, train_target) \n",
    "score_valid = lr_model.score(validate_features, validate_target) \n",
    "\n",
    "print(\"Accuracy of logistic regression model based on training set:\", score_train)\n",
    "print(\"Accuracy of logistic regression model based on validation set:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous two models, I do not need to specify the tree depth or number of trees hyperparameters. Instead, I only need to set the solver parameter, and in this case, I used liblinear. I kept the random_state parameter as 12345."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The random forest model achieved the highest score of 80.72% when validating the dataset. To obtain this level of accuracy, a model with 30 trees was analyzed.**\n",
    "\n",
    "**Considering these findings, it is concluded that the random forest model is the best choice. Although it requires more trees compared to the decision tree model, the increase is still manageable and provides a significant improvement in accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=30, random_state=54321)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final model\n",
    "final_model = RandomForestClassifier(random_state=54321, max_depth=10, n_estimators=30)\n",
    "final_model.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8102643856920684\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test_features dataset\n",
    "test_predictions = final_model.predict(test_features)\n",
    "\n",
    "#Test accuracy\n",
    "print('Accuracy score:', accuracy_score(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the higher accuracy score compared to the training results, this model is performing quite well.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    444\n",
       "1    199\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts the number of Smart (0) vs Ultra (1) on test_target\n",
    "test_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69.051322\n",
       "1    30.948678\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of users\n",
    "test_target.value_counts() / test_target.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieved an accuracy rate of 81.02%, which is approximately 12% higher than the majority class. This indicates that the model is able to effectively analyze the features and make accurate predictions. \n",
    "\n",
    "However, I'd like to highlight that there is a data imbalance. I observed that the test_target dataset consists of 69.05% Smart customers. Despite this imbalance, the model is still performing well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    78.693624\n",
       "1    21.306376\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the predicted counts of Smart (0) and Ultra (1) subscribers generated by the model:\n",
    "\n",
    "test_prediction_df = pd.DataFrame(test_predictions)\n",
    "test_prediction_df.value_counts() / test_prediction_df.shape[0] * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model predicts that 78.69% of the customers in the test dataset can be recommended to purchase the Smart plan. The model also predicts that a significantly larger number of customers can be offered the Smart package compared to the Ultra package. This observation aligns with the distribution in the test_target dataset.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After evaluating multiple models, including the decision tree and random forest, it is determined that the random forest model outperforms the others in terms of accuracy. This chosen model demonstrates good predictive performance and passes the sanity check process. Overall, it provides reliable predictions with a high level of accuracy.**\n",
    "\n",
    "**Based on my analysis and the performance of the chosen random forest model, my recommendation for Megaline would be to utilize this model to make package recommendations for their customers. The random forest model has demonstrated a high level of accuracy in predicting customer preferences between the Smart and Ultra packages.**\n",
    "\n",
    "**By leveraging this model, Megaline can effectively analyze customer behavior and recommend the appropriate package to customers who have not yet switched to the latest package. This approach will enable Megaline to optimize their offerings and cater to individual customer needs, ultimately leading to improved customer satisfaction and potentially higher subscription rates for the recommended package.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 776,
    "start_time": "2024-11-21T00:14:04.259Z"
   },
   {
    "duration": 17,
    "start_time": "2024-11-21T00:14:15.606Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-21T00:15:13.641Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-21T00:15:17.056Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T00:15:27.175Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T00:18:43.957Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T00:18:43.962Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T00:18:43.972Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T00:18:43.983Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T00:18:43.993Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T00:19:03.632Z"
   },
   {
    "duration": 170,
    "start_time": "2024-11-21T03:08:06.102Z"
   },
   {
    "duration": 809,
    "start_time": "2024-11-21T03:11:26.445Z"
   },
   {
    "duration": 12,
    "start_time": "2024-11-21T03:11:27.257Z"
   },
   {
    "duration": 12,
    "start_time": "2024-11-21T03:11:27.270Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-21T03:11:27.286Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T03:11:27.302Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-21T03:11:27.313Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T03:11:27.326Z"
   },
   {
    "duration": 160,
    "start_time": "2024-11-21T06:19:53.951Z"
   },
   {
    "duration": 840,
    "start_time": "2024-11-21T06:20:16.427Z"
   },
   {
    "duration": 17,
    "start_time": "2024-11-21T06:20:17.269Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:20:17.288Z"
   },
   {
    "duration": 12,
    "start_time": "2024-11-21T06:20:17.308Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:20:17.321Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:20:17.328Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-21T06:20:17.339Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:20:17.347Z"
   },
   {
    "duration": 29,
    "start_time": "2024-11-21T06:22:28.848Z"
   },
   {
    "duration": 243,
    "start_time": "2024-11-21T06:23:00.955Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-21T06:24:13.212Z"
   },
   {
    "duration": 44,
    "start_time": "2024-11-21T06:24:44.921Z"
   },
   {
    "duration": 77,
    "start_time": "2024-11-21T06:31:03.534Z"
   },
   {
    "duration": 20,
    "start_time": "2024-11-21T06:32:32.951Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T06:32:37.748Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:32:37.758Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:32:37.769Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:32:37.780Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:32:37.790Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:32:37.797Z"
   },
   {
    "duration": 21,
    "start_time": "2024-11-21T06:32:37.808Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:32:37.831Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:32:37.833Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:32:37.834Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:32:37.836Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T06:34:04.387Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-21T06:34:04.397Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:34:04.406Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:34:04.416Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:34:04.426Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:34:04.434Z"
   },
   {
    "duration": 16,
    "start_time": "2024-11-21T06:34:04.444Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:34:04.462Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:34:04.464Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:34:04.465Z"
   },
   {
    "duration": 0,
    "start_time": "2024-11-21T06:34:04.467Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T06:34:46.625Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T06:34:50.827Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:34:50.833Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:34:50.844Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-21T06:34:50.854Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:34:50.864Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:34:50.870Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-21T06:34:50.880Z"
   },
   {
    "duration": 21,
    "start_time": "2024-11-21T06:34:50.889Z"
   },
   {
    "duration": 16,
    "start_time": "2024-11-21T06:34:50.911Z"
   },
   {
    "duration": 245,
    "start_time": "2024-11-21T06:34:50.929Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:34:51.176Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T06:35:13.756Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:35:13.765Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:35:13.776Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:35:13.786Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-21T06:35:13.795Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-21T06:35:13.805Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:35:13.817Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-21T06:35:13.826Z"
   },
   {
    "duration": 16,
    "start_time": "2024-11-21T06:35:13.834Z"
   },
   {
    "duration": 252,
    "start_time": "2024-11-21T06:35:13.851Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:35:14.105Z"
   },
   {
    "duration": 68,
    "start_time": "2024-11-21T06:36:13.396Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:38:15.544Z"
   },
   {
    "duration": 336,
    "start_time": "2024-11-21T06:38:28.993Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T06:38:49.990Z"
   },
   {
    "duration": 1498,
    "start_time": "2024-11-21T06:38:57.528Z"
   },
   {
    "duration": 78,
    "start_time": "2024-11-21T06:45:41.091Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:45:57.097Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:46:23.040Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T06:48:14.893Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-21T06:48:21.769Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:51:51.587Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T06:56:10.837Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:56:10.843Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:56:10.854Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:56:10.864Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:56:10.873Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T06:56:10.879Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-21T06:56:10.890Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-21T06:56:10.898Z"
   },
   {
    "duration": 15,
    "start_time": "2024-11-21T06:56:10.914Z"
   },
   {
    "duration": 84,
    "start_time": "2024-11-21T06:56:10.930Z"
   },
   {
    "duration": 345,
    "start_time": "2024-11-21T06:56:11.016Z"
   },
   {
    "duration": 1492,
    "start_time": "2024-11-21T06:56:11.362Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-21T06:56:12.856Z"
   },
   {
    "duration": 84,
    "start_time": "2024-11-21T06:56:12.868Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:56:12.954Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T06:56:12.963Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-21T06:56:12.968Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-21T06:56:12.974Z"
   },
   {
    "duration": 779,
    "start_time": "2024-11-21T08:34:12.291Z"
   },
   {
    "duration": 15,
    "start_time": "2024-11-21T08:34:13.072Z"
   },
   {
    "duration": 16,
    "start_time": "2024-11-21T08:34:13.089Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-21T08:34:13.107Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-21T08:34:13.177Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-21T08:34:13.692Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-21T08:34:17.165Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-21T08:34:36.975Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-21T08:34:59.397Z"
   },
   {
    "duration": 17,
    "start_time": "2024-11-21T08:35:32.436Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
